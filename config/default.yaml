# Lead Scraper Configuration
# Target: US Local Businesses

targeting:
  country: US
  # Specify states (leave empty for all US states)
  states: []
  # Specify cities (leave empty for state-wide)
  cities: []
  # Target industries/categories
  categories:
    - restaurants
    - plumbers
    - electricians
    - dentists
    - lawyers
    - real estate agents
    - auto repair
    - salons
    - gyms
    - accountants

scraping:
  # Sources to scrape (in priority order)
  # googlemaps uses Playwright to scrape Google Maps — richest local data
  # yellowpages uses Playwright to render JS
  # yelp and bbb have aggressive bot detection — may require proxies
  sources:
    - googlemaps
    - yellowpages
    # - bbb    # Requires proxy — blocked without it
    # - yelp   # Requires proxy — blocked without it
  # Max leads per category per location
  max_leads_per_search: 100
  # Pages to scrape per search (for googlemaps: scroll batches)
  max_pages_per_search: 5

enrichment:
  enabled: true
  # Which enrichment modules to run (order matters!)
  # Discovery → contact crawling → social/tech/reviews → verification → scoring
  modules:
    - website_discovery       # Find website via Google when missing
    - deep_contact            # Crawl all pages for hidden emails/phones
    - email_discovery         # Find emails via Google/directories when missing
    - phone_discovery         # Find phone numbers when missing
    - website_tech_stack      # Detect CMS, analytics, tech stack
    - social_media            # Find Facebook, Instagram, LinkedIn, etc.
    - contact_enrichment      # Find owner name, title, LinkedIn
    - reviews_ratings         # Google/Yelp ratings and reviews
    - email_verification      # Verify emails (MX + SMTP probe)
    - icp_scoring             # Score leads on business fit (ICP)
  # Timeout for enrichment requests (seconds)
  timeout: 15

  # Re-enrichment settings
  re_enrichment:
    enabled: true
    # Re-enrich leads older than this many days
    stale_after_days: 30
    # Max leads to re-enrich per cycle
    max_per_cycle: 50

deduplication:
  enabled: true
  # Fields to match for deduplication
  match_fields:
    - phone
    - email
    - name_and_address

export:
  # Auto-export after scraping
  enabled: false
  format: csv  # csv, json
  output_dir: exports/

scheduling:
  enabled: false
  # Cron-style: run daily at 2 AM
  interval_hours: 24
  start_time: "02:00"
